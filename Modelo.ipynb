{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 32), (None, 32), (None, 12, 65), (None, 12, 16), (None, 12, 16)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\102140\\OneDrive - Grundfos\\Personal\\DATA SCIENCE\\Proyecto Galicia\\Modelo.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/102140/OneDrive%20-%20Grundfos/Personal/DATA%20SCIENCE/Proyecto%20Galicia/Modelo.ipynb#W1sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m dense_security \u001b[39m=\u001b[39m Dense(\u001b[39m16\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)(input_security)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/102140/OneDrive%20-%20Grundfos/Personal/DATA%20SCIENCE/Proyecto%20Galicia/Modelo.ipynb#W1sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Combinar todas las características\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/102140/OneDrive%20-%20Grundfos/Personal/DATA%20SCIENCE/Proyecto%20Galicia/Modelo.ipynb#W1sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m combined_features \u001b[39m=\u001b[39m Concatenate()([embedding_id, embedding_client, lstm_output, dense_risk, dense_security])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/102140/OneDrive%20-%20Grundfos/Personal/DATA%20SCIENCE/Proyecto%20Galicia/Modelo.ipynb#W1sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m# Capa de salida para clasificación de seguros\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/102140/OneDrive%20-%20Grundfos/Personal/DATA%20SCIENCE/Proyecto%20Galicia/Modelo.ipynb#W1sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m output \u001b[39m=\u001b[39m Dense(\u001b[39m3\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)(combined_features)\n",
      "File \u001b[1;32mc:\\Users\\102140\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\102140\\Anaconda3\\envs\\dhdsblend2021\\lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py:119\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    117\u001b[0m ranks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mlen\u001b[39m(shape) \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m shape_set)\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ranks) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m    120\u001b[0m \u001b[39m# Get the only rank for the set.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m (rank,) \u001b[39m=\u001b[39m ranks\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 32), (None, 32), (None, 12, 65), (None, 12, 16), (None, 12, 16)]"
     ]
    }
   ],
   "source": [
    "# Generar datos de ejemplo (simulados)\n",
    "np.random.seed(0)\n",
    "n_samples = 1000\n",
    "n_timesteps = 12  # 12 meses de datos\n",
    "\n",
    "# Características del cliente: Edad, Ingresos, Localidad (1-5), Tipo de Industria (1-3)\n",
    "X_client = np.random.uniform(18, 65, size=(n_samples, 4))\n",
    "X_income = np.random.uniform(20000, 100000, size=(n_samples, 1))\n",
    "X_location = np.random.randint(1, 6, size=(n_samples, 1))\n",
    "X_industry = np.random.randint(1, 4, size=(n_samples, 1))\n",
    "\n",
    "# ID del cliente (identificador único)\n",
    "client_ids = np.arange(1, n_samples + 1).reshape(-1, 1)\n",
    "\n",
    "# Series temporales de coberturas adquiridas (simuladas como valores binarios)\n",
    "X_coverages = np.random.randint(2, size=(n_samples, n_timesteps, 3))\n",
    "\n",
    "# Series temporales de contactos del cliente (simuladas como valores binarios)\n",
    "X_contacts = np.random.randint(2, size=(n_samples, n_timesteps, 1))\n",
    "\n",
    "# Características de riesgo por desastres naturales y seguridad por robo por provincia (simuladas)\n",
    "X_risk_features = np.random.rand(n_samples, n_timesteps, 2)\n",
    "X_security_features = np.random.rand(n_samples, n_timesteps, 2)\n",
    "\n",
    "# Objetivo: Recomendación de seguros (etiquetas codificadas en one-hot)\n",
    "y = np.random.randint(2, size=(n_samples, n_timesteps, 3))\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "split_ratio = 0.8\n",
    "split_index = int(n_samples * split_ratio)\n",
    "\n",
    "X_client_train = X_client[:split_index]\n",
    "X_client_test = X_client[split_index:]\n",
    "client_ids_train = client_ids[:split_index]\n",
    "client_ids_test = client_ids[split_index:]\n",
    "X_coverages_train = X_coverages[:split_index]\n",
    "X_coverages_test = X_coverages[split_index:]\n",
    "X_contacts_train = X_contacts[:split_index]\n",
    "X_contacts_test = X_contacts[split_index:]\n",
    "X_risk_train = X_risk_features[:split_index]\n",
    "X_risk_test = X_risk_features[split_index:]\n",
    "X_security_train = X_security_features[:split_index]\n",
    "X_security_test = X_security_features[split_index:]\n",
    "y_train = y[:split_index]\n",
    "y_test = y[split_index:]\n",
    "\n",
    "# Definir la arquitectura del modelo\n",
    "input_client = Input(shape=(4,))\n",
    "input_coverages = Input(shape=(n_timesteps, 3))\n",
    "input_contacts = Input(shape=(n_timesteps, 1))\n",
    "input_risk = Input(shape=(n_timesteps, 2))\n",
    "input_security = Input(shape=(n_timesteps, 2))\n",
    "input_id = Input(shape=(1,))\n",
    "\n",
    "# Capa de embeddings para el ID del cliente\n",
    "embedding_id = Embedding(input_dim=n_samples + 1, output_dim=32)(input_id)\n",
    "embedding_id = tf.reduce_mean(embedding_id, axis=1)\n",
    "\n",
    "# Capa de embeddings para características del cliente\n",
    "embedding_client = Dense(32, activation='relu')(input_client)\n",
    "\n",
    "# Capa LSTM para series temporales de coberturas adquiridas y contactos del cliente\n",
    "lstm_output = LSTM(64, return_sequences=True)(input_coverages)\n",
    "lstm_output = Concatenate(axis=-1)([lstm_output, input_contacts])\n",
    "\n",
    "# Capa densa para características de riesgo y seguridad\n",
    "dense_risk = Dense(16, activation='relu')(input_risk)\n",
    "dense_security = Dense(16, activation='relu')(input_security)\n",
    "\n",
    "# Combinar todas las características\n",
    "combined_features = Concatenate()([embedding_id, embedding_client, lstm_output, dense_risk, dense_security])\n",
    "\n",
    "# Capa de salida para clasificación de seguros\n",
    "output = Dense(3, activation='softmax')(combined_features)\n",
    "\n",
    "# Construir el modelo\n",
    "model = Model(inputs=[input_client, input_coverages, input_contacts, input_risk, input_security, input_id], outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit([X_client_train, X_coverages_train, X_contacts_train, X_risk_train, X_security_train, client_ids_train],\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          validation_data=([X_client_test, X_coverages_test, X_contacts_test, X_risk_test, X_security_test, client_ids_test], y_test))\n",
    "\n",
    "# Hacer predicciones (por ejemplo, para un nuevo cliente y mes)\n",
    "new_client_id = np.array([[n_samples + 1]])  # ID de cliente nuevo\n",
    "new_client_features = np.array([[35, 60000, 3, 2]])  # Ejemplo de características de cliente nuevo\n",
    "new_coverages = np.random.randint(2, size=(1, n_timesteps, 3))  # Ejemplo de series temporales de coberturas\n",
    "new_contacts = np.random.randint(2, size=(1, n_timesteps, 1))  # Ejemplo de series temporales de contactos\n",
    "new_risk = np.random.rand(1, n_timesteps, 2)  # Ejemplo de características de riesgo\n",
    "new_security = np.random.rand\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dhdsblend2021",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
